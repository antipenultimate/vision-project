{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import keras\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fer2013():\n",
    "    if not os.path.exists(\"fer2013\"):\n",
    "        print(\"Downloading the face emotion dataset...\")\n",
    "        subprocess.check_output(\"curl -SL https://www.dropbox.com/s/opuvvdv3uligypx/fer2013.tar | tar xz\", shell=True)\n",
    "    data = pd.read_csv(\"fer2013/fer2013.csv\")\n",
    "    pixels = data['pixels'].tolist()\n",
    "    width, height = 48, 48\n",
    "    faces = []\n",
    "    for pixel_sequence in pixels:\n",
    "        face = np.asarray(pixel_sequence.split(' '), dtype=np.uint8).reshape(width, height)\n",
    "        face = cv2.resize(face.astype('uint8'), (width, height))\n",
    "        faces.append(face.astype('float32'))\n",
    "\n",
    "    faces = np.asarray(faces)\n",
    "    faces = np.expand_dims(faces, -1)\n",
    "    emotions = pd.get_dummies(data['emotion']).as_matrix()\n",
    "\n",
    "    val_faces = faces[int(len(faces) * 0.8):]\n",
    "    val_emotions = emotions[int(len(faces) * 0.8):]\n",
    "    train_faces = faces[:int(len(faces) * 0.8)]\n",
    "    train_emotions = emotions[:int(len(faces) * 0.8)]\n",
    "    \n",
    "    return train_faces, train_emotions, val_faces, val_emotions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# loading dataset\n",
    "\n",
    "train_faces, train_emotions, val_faces, val_emotions = load_fer2013()\n",
    "num_samples, num_classes = train_emotions.shape\n",
    "\n",
    "train_faces /= 255.\n",
    "val_faces /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 48, 48, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_faces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = run.config\n",
    "\n",
    "config.batch_size = 32\n",
    "#config.num_epochs = 20\n",
    "\n",
    "input_shape = (48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Added from cnn.py\n",
    "#config = run.config\n",
    "config.first_layer_convs = 32\n",
    "config.first_layer_conv_width = 3\n",
    "config.first_layer_conv_height = 3\n",
    "#config.dropout = 0.2\n",
    "config.dense_layer_size = 128\n",
    "#config.img_width = 28\n",
    "#config.img_height = 28\n",
    "config.num_epochs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B Run: https://app.wandb.ai/qualcomm/emotion-aug21/runs/3m7nbfcg\n",
      "Wrap your training loop with `with wandb.monitor():` to display live results.\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 7178 samples\n",
      "Epoch 1/32\n",
      "28709/28709 [==============================] - 24s 852us/step - loss: 1.8038 - acc: 0.2544 - val_loss: 1.8519 - val_acc: 0.2282\n",
      "Epoch 2/32\n",
      "28709/28709 [==============================] - 22s 775us/step - loss: 1.7336 - acc: 0.3005 - val_loss: 1.8542 - val_acc: 0.2458\n",
      "Epoch 3/32\n",
      "28709/28709 [==============================] - 22s 777us/step - loss: 1.6785 - acc: 0.3328 - val_loss: 1.7227 - val_acc: 0.3123\n",
      "Epoch 4/32\n",
      "28709/28709 [==============================] - 22s 778us/step - loss: 1.6405 - acc: 0.3519 - val_loss: 1.6534 - val_acc: 0.3381\n",
      "Epoch 5/32\n",
      "28709/28709 [==============================] - 22s 781us/step - loss: 1.6042 - acc: 0.3739 - val_loss: 1.6533 - val_acc: 0.3452\n",
      "Epoch 6/32\n",
      "28709/28709 [==============================] - 23s 785us/step - loss: 1.5756 - acc: 0.3844 - val_loss: 1.5566 - val_acc: 0.3929\n",
      "Epoch 7/32\n",
      "28709/28709 [==============================] - 22s 780us/step - loss: 1.5564 - acc: 0.3913 - val_loss: 1.5724 - val_acc: 0.3743\n",
      "Epoch 8/32\n",
      "28709/28709 [==============================] - 22s 775us/step - loss: 1.5450 - acc: 0.3947 - val_loss: 1.5501 - val_acc: 0.3807\n",
      "Epoch 9/32\n",
      "28709/28709 [==============================] - 22s 773us/step - loss: 1.5217 - acc: 0.4044 - val_loss: 1.6577 - val_acc: 0.3463\n",
      "Epoch 10/32\n",
      "28709/28709 [==============================] - 22s 773us/step - loss: 1.5102 - acc: 0.4109 - val_loss: 1.5495 - val_acc: 0.3748\n",
      "Epoch 11/32\n",
      "28709/28709 [==============================] - 22s 778us/step - loss: 1.4951 - acc: 0.4173 - val_loss: 1.5436 - val_acc: 0.3824\n",
      "Epoch 12/32\n",
      "28709/28709 [==============================] - 22s 775us/step - loss: 1.4874 - acc: 0.4239 - val_loss: 1.5315 - val_acc: 0.3883\n",
      "Epoch 13/32\n",
      "28709/28709 [==============================] - 22s 780us/step - loss: 1.4734 - acc: 0.4241 - val_loss: 1.5171 - val_acc: 0.4014\n",
      "Epoch 14/32\n",
      "28709/28709 [==============================] - 22s 778us/step - loss: 1.4631 - acc: 0.4309 - val_loss: 1.5304 - val_acc: 0.3936\n",
      "Epoch 15/32\n",
      "28709/28709 [==============================] - 22s 776us/step - loss: 1.4564 - acc: 0.4361 - val_loss: 1.4890 - val_acc: 0.4121\n",
      "Epoch 16/32\n",
      "28709/28709 [==============================] - 22s 771us/step - loss: 1.4391 - acc: 0.4369 - val_loss: 1.4479 - val_acc: 0.4270\n",
      "Epoch 17/32\n",
      "28709/28709 [==============================] - 22s 771us/step - loss: 1.4311 - acc: 0.4451 - val_loss: 1.4640 - val_acc: 0.4284\n",
      "Epoch 18/32\n",
      "28709/28709 [==============================] - 22s 776us/step - loss: 1.4147 - acc: 0.4523 - val_loss: 1.4233 - val_acc: 0.4355\n",
      "Epoch 19/32\n",
      "28709/28709 [==============================] - 22s 773us/step - loss: 1.4105 - acc: 0.4523 - val_loss: 1.4478 - val_acc: 0.4348\n",
      "Epoch 20/32\n",
      "28709/28709 [==============================] - 22s 773us/step - loss: 1.4098 - acc: 0.4537 - val_loss: 1.4203 - val_acc: 0.4413\n",
      "Epoch 21/32\n",
      "28709/28709 [==============================] - 22s 773us/step - loss: 1.3996 - acc: 0.4570 - val_loss: 1.4744 - val_acc: 0.4356\n",
      "Epoch 22/32\n",
      "28709/28709 [==============================] - 22s 774us/step - loss: 1.3860 - acc: 0.4614 - val_loss: 1.3623 - val_acc: 0.4713\n",
      "Epoch 23/32\n",
      "28709/28709 [==============================] - 22s 773us/step - loss: 1.3851 - acc: 0.4629 - val_loss: 1.4289 - val_acc: 0.4464\n",
      "Epoch 24/32\n",
      "28709/28709 [==============================] - 22s 781us/step - loss: 1.3764 - acc: 0.4670 - val_loss: 1.3601 - val_acc: 0.4739\n",
      "Epoch 25/32\n",
      "28709/28709 [==============================] - 22s 781us/step - loss: 1.3621 - acc: 0.4729 - val_loss: 1.3461 - val_acc: 0.4794\n",
      "Epoch 26/32\n",
      "28709/28709 [==============================] - 22s 782us/step - loss: 1.3573 - acc: 0.4736 - val_loss: 1.4053 - val_acc: 0.4592\n",
      "Epoch 27/32\n",
      "28709/28709 [==============================] - 22s 780us/step - loss: 1.3572 - acc: 0.4778 - val_loss: 1.4610 - val_acc: 0.4363\n",
      "Epoch 28/32\n",
      "28709/28709 [==============================] - 22s 781us/step - loss: 1.3545 - acc: 0.4751 - val_loss: 1.3334 - val_acc: 0.4852\n",
      "Epoch 29/32\n",
      "28709/28709 [==============================] - 23s 794us/step - loss: 1.3477 - acc: 0.4807 - val_loss: 1.4068 - val_acc: 0.4554\n",
      "Epoch 30/32\n",
      "28709/28709 [==============================] - 23s 805us/step - loss: 1.3423 - acc: 0.4827 - val_loss: 1.3665 - val_acc: 0.4713\n",
      "Epoch 31/32\n",
      "28709/28709 [==============================] - 22s 777us/step - loss: 1.3406 - acc: 0.4851 - val_loss: 1.3519 - val_acc: 0.4742\n",
      "Epoch 32/32\n",
      "28709/28709 [==============================] - 22s 777us/step - loss: 1.3317 - acc: 0.4847 - val_loss: 1.4393 - val_acc: 0.4531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff0ed39ed68>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing\n",
    "#config.num_epochs = 32\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,\n",
    "    (config.first_layer_conv_width, config.first_layer_conv_height),\n",
    "    input_shape=(48, 48,1),\n",
    "    padding='valid',\n",
    "    activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(32,\n",
    "    (config.first_layer_conv_width, config.first_layer_conv_height),\n",
    "    #input_shape=(48, 48,1),\n",
    "    padding='valid',\n",
    "    activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(32,\n",
    "    (config.first_layer_conv_width, config.first_layer_conv_height),\n",
    "    #input_shape=(48, 48,1),\n",
    "    padding='valid',\n",
    "    activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(32,\n",
    "    (config.first_layer_conv_width, config.first_layer_conv_height),\n",
    "    #input_shape=(48, 48,1),\n",
    "    padding='valid',\n",
    "    activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(32,\n",
    "    (config.first_layer_conv_width, config.first_layer_conv_height),\n",
    "    #input_shape=(48, 48,1),\n",
    "    padding='valid',\n",
    "    activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Flatten(input_shape=input_shape))\n",
    "model.add(Dense(config.dense_layer_size, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "\n",
    "#model.load_weights(\"emotion.h5\")\n",
    "\n",
    "model.fit(train_faces, train_emotions, batch_size=config.batch_size,\n",
    "        epochs=config.num_epochs, verbose=1, callbacks=[\n",
    "            WandbCallback(data_type=\"image\", labels=[\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"])\n",
    "        ], validation_data=(val_faces, val_emotions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"emotion.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
