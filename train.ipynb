{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import keras\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fer2013():\n",
    "    if not os.path.exists(\"fer2013\"):\n",
    "        print(\"Downloading the face emotion dataset...\")\n",
    "        subprocess.check_output(\"curl -SL https://www.dropbox.com/s/opuvvdv3uligypx/fer2013.tar | tar xz\", shell=True)\n",
    "    data = pd.read_csv(\"fer2013/fer2013.csv\")\n",
    "    pixels = data['pixels'].tolist()\n",
    "    width, height = 48, 48\n",
    "    faces = []\n",
    "    for pixel_sequence in pixels:\n",
    "        face = np.asarray(pixel_sequence.split(' '), dtype=np.uint8).reshape(width, height)\n",
    "        face = cv2.resize(face.astype('uint8'), (width, height))\n",
    "        faces.append(face.astype('float32'))\n",
    "\n",
    "    faces = np.asarray(faces)\n",
    "    faces = np.expand_dims(faces, -1)\n",
    "    emotions = pd.get_dummies(data['emotion']).as_matrix()\n",
    "\n",
    "    val_faces = faces[int(len(faces) * 0.8):]\n",
    "    val_emotions = emotions[int(len(faces) * 0.8):]\n",
    "    train_faces = faces[:int(len(faces) * 0.8)]\n",
    "    train_emotions = emotions[:int(len(faces) * 0.8)]\n",
    "    \n",
    "    return train_faces, train_emotions, val_faces, val_emotions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# loading dataset\n",
    "\n",
    "train_faces, train_emotions, val_faces, val_emotions = load_fer2013()\n",
    "num_samples, num_classes = train_emotions.shape\n",
    "\n",
    "train_faces /= 255.\n",
    "val_faces /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 48, 48, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_faces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        #rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        #rescale=1./255,\n",
    "        #shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "datagen.fit(train_faces, augment=True, rounds=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (48, 48, 1)\n",
    "\n",
    "config = run.config\n",
    "\n",
    "#config.first_layer_convs = 32\n",
    "#config.first_layer_conv_width = 3\n",
    "#config.first_layer_conv_height = 3\n",
    "#config.dropout = 0.2\n",
    "#config.dense_layer_size = 128\n",
    "#config.img_width = 28\n",
    "#config.img_height = 28\n",
    "config.num_epochs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B Run: https://app.wandb.ai/qualcomm/emotion-aug21/runs/5cou83o5\n",
      "Wrap your training loop with `with wandb.monitor():` to display live results.\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "886/897 [============================>.] - ETA: 0s - loss: 1.8042 - acc: 0.2489"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), \n",
    "    #(config.first_layer_conv_width, config.first_layer_conv_height),\n",
    "    input_shape=(48, 48,1),\n",
    "    padding='valid',\n",
    "    activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), \n",
    "    padding='valid',\n",
    "    activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), \n",
    "    padding='valid',\n",
    "    activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4*64*7, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "\n",
    "#model.load_weights(\"emotion.h5\")\n",
    "\n",
    "#model.fit(train_faces, train_emotions, batch_size=32,\n",
    "#        epochs=config.num_epochs, verbose=1, callbacks=[\n",
    "#            WandbCallback(data_type=\"image\", labels=[\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"])\n",
    "#        ], validation_data=(val_faces, val_emotions))\n",
    "\n",
    "\n",
    "train_generator = datagen.flow(train_faces, train_emotions, batch_size=32)\n",
    "val_generator = datagen.flow(val_faces, val_emotions, batch_size=32)\n",
    "model.fit_generator(train_generator,\n",
    "            steps_per_epoch=len(train_faces)//32, \n",
    "            epochs=config.num_epochs, verbose=1,\n",
    "            #callbacks=[\n",
    "            #    WandbCallback(data_type=\"image\", labels=[\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"])\n",
    "            #],\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=len(val_faces)//32)\n",
    "\n",
    "\n",
    "#for e in range(config.num_epochs):\n",
    "#    print(\"Epoch\", e)\n",
    "#    batches = 0\n",
    "#    for (x_batch, y_batch), (val_x, val_y) in zip(\n",
    "#                    datagen.flow(train_faces, train_emotions, batch_size=32),\n",
    "#                    datagen.flow(val_faces, val_emotions, batch_size=32)):\n",
    "#        model.fit(x_batch, y_batch, validation_data=(val_x, val_y), verbose=0)\n",
    "#        batches += 1\n",
    "#        if batches >= len(train_faces) / 32:\n",
    "#            break\n",
    "#    model.evaluate(val_faces, val_emotions)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "897"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_faces)//32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"emotion.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
